{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041fb469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graph samples: 100\n",
      "Number of nodes per graph: 306\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Required imports\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# üìÇ Step 1: Load the data\n",
    "csv_file = \"hgcal_gcn_training_layer1_combined.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# üßπ Step 2: Extract wafer names and coordinates (from uX_vY)\n",
    "feature_cols = df.columns[1:]  # Skip lumi column\n",
    "uv_coords = []\n",
    "\n",
    "for col in feature_cols:\n",
    "    match = re.match(r\"u(-?\\d+)_v(-?\\d+)\", col)\n",
    "    if match:\n",
    "        u, v = int(match.group(1)), int(match.group(2))\n",
    "        uv_coords.append((u, v))\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid wafer column format: {col}\")\n",
    "\n",
    "# üß± Step 3: Convert coordinates to 2D positions\n",
    "coord_tensor = torch.tensor(uv_coords, dtype=torch.float)\n",
    "\n",
    "# üßÆ Step 4: Compute edge index using k-nearest neighbors (e.g., k=6)\n",
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "edge_index = knn_graph(coord_tensor, k=6)\n",
    "\n",
    "# üìè Step 5: Normalize the features (occupancy)\n",
    "features = df[feature_cols].values\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(features)\n",
    "\n",
    "# üì¶ Step 6: Create list of PyG Data objects (one per lumi)\n",
    "data_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    x = torch.tensor(normalized_features[i], dtype=torch.float).unsqueeze(1)  # shape (N, 1)\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    data_list.append(data)\n",
    "\n",
    "# üß≥ Optional: Create DataLoader\n",
    "batch_size = 8\n",
    "loader = DataLoader(data_list, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"Number of graph samples: {len(data_list)}\")\n",
    "print(f\"Number of nodes per graph: {x.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a993a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, latent_dim):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Encode node features into latent space\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GCNDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_channels, out_channels):\n",
    "        super(GCNDecoder, self).__init__()\n",
    "        self.conv1 = GCNConv(latent_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        # Decode latent representation back to original features\n",
    "        z = self.conv1(z, edge_index)\n",
    "        z = F.relu(z)\n",
    "        z = self.conv2(z, edge_index)\n",
    "        return z\n",
    "\n",
    "class GCNAutoEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=1, hidden_channels=32, latent_dim=16):\n",
    "        super(GCNAutoEncoder, self).__init__()\n",
    "        self.encoder = GCNEncoder(in_channels, hidden_channels, latent_dim)\n",
    "        self.decoder = GCNDecoder(latent_dim, hidden_channels, in_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # Encode to latent space\n",
    "        z = self.encoder(x, edge_index)\n",
    "        \n",
    "        # Optionally do pooling or anomaly detection here using `z` and `batch`\n",
    "        # For now, we just reconstruct node-wise features\n",
    "        out = self.decoder(z, edge_index)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59eb4fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# üî• Step 7: Setup training - loss function and optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = GCNAutoEncoder(in_channels=1, hidden_channels=32, latent_dim=16).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b6e9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.853485\n",
      "Epoch 2/10, Loss: 0.814506\n",
      "Epoch 3/10, Loss: 0.811804\n",
      "Epoch 4/10, Loss: 0.811379\n",
      "Epoch 5/10, Loss: 0.812889\n",
      "Epoch 6/10, Loss: 0.811750\n",
      "Epoch 7/10, Loss: 0.810910\n",
      "Epoch 8/10, Loss: 0.814934\n",
      "Epoch 9/10, Loss: 0.810457\n",
      "Epoch 10/10, Loss: 0.810137\n"
     ]
    }
   ],
   "source": [
    "# üî• Step 8: Training loop (simple version)\n",
    "\n",
    "num_epochs = 10\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        loss = criterion(out, batch.x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "    avg_loss = total_loss / len(data_list)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
